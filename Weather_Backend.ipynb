{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weather-Backend.ipynb",
      "provenance": [],
      "mount_file_id": "1DwD2lwYrK09VSofV47ieok3lsdL-aqiC",
      "authorship_tag": "ABX9TyPccDa0kDvO+q/5cvBChZOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhutikcodes/weather-prediction-ml-model-analysis/blob/main/Weather_Backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JCF3aIqJw_w",
        "outputId": "25ccf149-8c62-4c7a-d0cc-64ec2b553c61",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n",
            "Requirement already satisfied: keras==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.22.3 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0, 1.13.1, 1.13.3, 1.14.0rc1, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0rc1, 1.17.0rc2, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0rc1, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0rc1, 1.19.0rc2, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0rc1, 1.20.0rc2, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0rc1, 1.21.0rc2, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for numpy==1.22.3\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pandas==1.4.2 (from versions: 0.1, 0.2, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.21.0, 0.21.1, 0.22.0, 0.23.0, 0.23.1, 0.23.2, 0.23.3, 0.23.4, 0.24.0, 0.24.1, 0.24.2, 0.25.0, 0.25.1, 0.25.2, 0.25.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pandas==1.4.2\u001b[0m\n",
            "Requirement already satisfied: scikit_learn==1.0.2 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-cpu==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (3.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (0.25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.46.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (14.0.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.8.0) (4.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-cpu==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-cpu==2.8.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (3.3.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-cpu==2.8.0) (3.2.0)\n",
            "Requirement already satisfied: flask_cors==3.0.10 in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors==3.0.10) (1.15.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask_cors==3.0.10) (0.12.2)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors==3.0.10) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors==3.0.10) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors==3.0.10) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors==3.0.10) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.9->flask_cors==3.0.10) (2.0.1)\n",
            "Requirement already satisfied: pyngrok==4.1.1 in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Pip Install\n",
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2 \n",
        "!pip install keras==2.8.0\n",
        "!pip install numpy==1.22.3\n",
        "!pip install pandas==1.4.2\n",
        "!pip install scikit_learn==1.0.2\n",
        "!pip install tensorflow-cpu==2.8.0\n",
        "!pip install flask_cors==3.0.10\n",
        "!pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Sytem commands\n",
        "# Copyright 2018 Google Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Colab-specific system command helpers.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import contextlib\n",
        "import locale\n",
        "import os\n",
        "import pty\n",
        "import select\n",
        "import signal\n",
        "import subprocess\n",
        "import sys\n",
        "import termios\n",
        "import time\n",
        "\n",
        "from IPython.core import magic_arguments\n",
        "from IPython.utils import text\n",
        "import six\n",
        "from google.colab import _ipython\n",
        "from google.colab import _message\n",
        "from google.colab.output import _tags\n",
        "\n",
        "# Linux read(2) limits to 0x7ffff000 so stay under that for clarity.\n",
        "_PTY_READ_MAX_BYTES_FOR_TEST = 2**20  # 1MB\n",
        "\n",
        "_BIN_BASH = os.environ.get('BIN_BASH_OVERRIDE_FOR_TEST', '/bin/bash')\n",
        "_ENCODING = 'UTF-8'\n",
        "\n",
        "\n",
        "def _shell_line_magic(line):\n",
        "  \"\"\"Runs a shell command, allowing input to be provided.\n",
        "  This is similar to Jupyter's `!` magic, but additionally allows input to be\n",
        "  provided to the subprocess. If the subprocess returns a non-zero exit code\n",
        "  a `subprocess.CalledProcessError` is raised. The provided command is run\n",
        "  within a bash shell.\n",
        "  Also available as a cell magic.\n",
        "  Usage:\n",
        "    # Returns a ShellResult.\n",
        "    f = %shell echo \"hello\"\n",
        "  Args:\n",
        "    line: The shell command to execute.\n",
        "  Returns:\n",
        "    ShellResult containing the results of the executed command.\n",
        "  Raises:\n",
        "    subprocess.CalledProcessError: If the subprocess exited with a non-zero\n",
        "      exit code.\n",
        "  \"\"\"\n",
        "  result = _run_command(line, clear_streamed_output=False)\n",
        "  result.check_returncode()\n",
        "  return result\n",
        "\n",
        "\n",
        "@magic_arguments.magic_arguments()\n",
        "@magic_arguments.argument(\n",
        "    '--ignore-errors',\n",
        "    dest='ignore_errors',\n",
        "    action='store_true',\n",
        "    help=('Don\\'t raise a `subprocess.CalledProcessError` when the '\n",
        "          'subprocess returns a non-0 exit code.'))\n",
        "def _shell_cell_magic(args, cmd):\n",
        "  \"\"\"Run the cell via a shell command, allowing input to be provided.\n",
        "  Also available as a line magic.\n",
        "  Usage:\n",
        "    # Returns a ShellResult.\n",
        "    %%shell\n",
        "    echo \"hello\"\n",
        "  This is similar to Jupyter's `!` magic, but additionally allows input to be\n",
        "  provided to the subprocess. By default, if the subprocess returns a non-zero\n",
        "  exit code a `subprocess.CalledProcessError` is raised. The provided command\n",
        "  is run within a bash shell.\n",
        "  Args:\n",
        "    args: Optional arguments.\n",
        "    cmd: The shell command to execute.\n",
        "  Returns:\n",
        "    ShellResult containing the results of the executed command.\n",
        "  Raises:\n",
        "    subprocess.CalledProcessError: If the subprocess exited with a non-zero\n",
        "      exit code and the `ignore_errors` argument wasn't provided.\n",
        "  \"\"\"\n",
        "\n",
        "  parsed_args = magic_arguments.parse_argstring(_shell_cell_magic, args)\n",
        "\n",
        "  result = _run_command(cmd, clear_streamed_output=False)\n",
        "  if not parsed_args.ignore_errors:\n",
        "    result.check_returncode()\n",
        "  return result\n",
        "\n",
        "\n",
        "class ShellResult(object):\n",
        "  \"\"\"Result of an invocation of the shell magic.\n",
        "  Note: This is intended to mimic subprocess.CompletedProcess, but has slightly\n",
        "  different characteristics, including:\n",
        "    * CompletedProcess has separate stdout/stderr properties. A ShellResult\n",
        "      has a single property containing the merged stdout/stderr stream,\n",
        "      providing compatibility with the existing \"!\" shell magic (which this is\n",
        "      intended to provide an alternative to).\n",
        "    * A custom __repr__ method that returns output. When the magic is invoked as\n",
        "      the only statement in the cell, Python prints the string representation by\n",
        "      default. The existing \"!\" shell magic also returns output.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, args, returncode, command_output):\n",
        "    self.args = args\n",
        "    self.returncode = returncode\n",
        "    self.output = command_output\n",
        "\n",
        "  def check_returncode(self):\n",
        "    if self.returncode:\n",
        "      raise subprocess.CalledProcessError(\n",
        "          returncode=self.returncode, cmd=self.args, output=self.output)\n",
        "\n",
        "  def _repr_pretty_(self, p, cycle):  # pylint:disable=unused-argument\n",
        "    # Note: When invoking the magic and not assigning the result\n",
        "    # (e.g. %shell echo \"foo\"), Python's default semantics will be used and\n",
        "    # print the string representation of the object. By default, this will\n",
        "    # display the __repr__ of ShellResult. Suppress this representation since\n",
        "    # the output of the command has already been displayed to the output window.\n",
        "    if cycle:\n",
        "      raise NotImplementedError\n",
        "\n",
        "\n",
        "def _configure_term_settings(pty_fd):\n",
        "  term_settings = termios.tcgetattr(pty_fd)\n",
        "  # ONLCR transforms NL to CR-NL, which is undesirable. Ensure this is disabled.\n",
        "  # http://man7.org/linux/man-pages/man3/termios.3.html\n",
        "  term_settings[1] &= ~termios.ONLCR\n",
        "\n",
        "  # ECHOCTL echoes control characters, which is undesirable.\n",
        "  term_settings[3] &= ~termios.ECHOCTL\n",
        "\n",
        "  termios.tcsetattr(pty_fd, termios.TCSANOW, term_settings)\n",
        "\n",
        "\n",
        "def _run_command(cmd, clear_streamed_output):\n",
        "  \"\"\"Calls the shell command, forwarding input received on the stdin_socket.\"\"\"\n",
        "  locale_encoding = locale.getpreferredencoding()\n",
        "  if locale_encoding != _ENCODING:\n",
        "    raise NotImplementedError(\n",
        "        'A UTF-8 locale is required. Got {}'.format(locale_encoding))\n",
        "\n",
        "  parent_pty, child_pty = pty.openpty()\n",
        "  _configure_term_settings(child_pty)\n",
        "\n",
        "  epoll = select.epoll()\n",
        "  epoll.register(\n",
        "      parent_pty,\n",
        "      (select.EPOLLIN | select.EPOLLOUT | select.EPOLLHUP | select.EPOLLERR))\n",
        "\n",
        "  stdin = child_pty\n",
        "  if os.getenv('COLAB_DISABLE_STDIN_FOR_SHELL_MAGICS', None):\n",
        "    stdin = os.open(os.devnull, os.O_RDWR)\n",
        "  try:\n",
        "    temporary_clearer = _tags.temporary if clear_streamed_output else _no_op\n",
        "\n",
        "    with temporary_clearer(), _display_stdin_widget(\n",
        "        delay_millis=500) as update_stdin_widget:\n",
        "      # TODO(b/115531839): Ensure that subprocesses are terminated upon\n",
        "      # interrupt.\n",
        "      p = subprocess.Popen(\n",
        "          cmd,\n",
        "          shell=True,\n",
        "          executable=_BIN_BASH,\n",
        "          stdout=child_pty,\n",
        "          stdin=stdin,\n",
        "          stderr=child_pty,\n",
        "          close_fds=True)\n",
        "      # The child PTY is only needed by the spawned process.\n",
        "      os.close(child_pty)\n",
        "\n",
        "      return _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget)\n",
        "  finally:\n",
        "    epoll.close()\n",
        "    os.close(parent_pty)\n",
        "\n",
        "\n",
        "class _MonitorProcessState(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.process_output = six.StringIO()\n",
        "    self.is_pty_still_connected = True\n",
        "\n",
        "\n",
        "def _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget):\n",
        "  \"\"\"Monitors the given subprocess until it terminates.\"\"\"\n",
        "  state = _MonitorProcessState()\n",
        "\n",
        "  # A single UTF-8 character can span multiple bytes. os.read returns bytes and\n",
        "  # could return a partial byte sequence for a UTF-8 character. Using an\n",
        "  # incremental decoder is incrementally fed input bytes and emits UTF-8\n",
        "  # characters.\n",
        "  # In order to be consistent with IPython's treatment of non-UTF-8 output, make\n",
        "  # use of the \"replace\" error handler within the decoder.\n",
        "  # https://github.com/ipython/ipykernel/blob/master/ipykernel/iostream.py.\n",
        "  decoder = codecs.getincrementaldecoder(_ENCODING)(errors='replace')\n",
        "\n",
        "  num_interrupts = 0\n",
        "  echo_status = None\n",
        "  while True:\n",
        "    try:\n",
        "      result = _poll_process(parent_pty, epoll, p, cmd, decoder, state)\n",
        "      if result is not None:\n",
        "        return result\n",
        "\n",
        "      term_settings = termios.tcgetattr(parent_pty)\n",
        "      new_echo_status = bool(term_settings[3] & termios.ECHO)\n",
        "      if echo_status != new_echo_status:\n",
        "        update_stdin_widget(new_echo_status)\n",
        "        echo_status = new_echo_status\n",
        "    except KeyboardInterrupt:\n",
        "      try:\n",
        "        num_interrupts += 1\n",
        "        if num_interrupts == 1:\n",
        "          p.send_signal(signal.SIGINT)\n",
        "        elif num_interrupts == 2:\n",
        "          # Process isn't responding to SIGINT and user requested another\n",
        "          # interrupt. Attempt to send SIGTERM followed by a SIGKILL if the\n",
        "          # process doesn't respond.\n",
        "          p.send_signal(signal.SIGTERM)\n",
        "          time.sleep(0.5)\n",
        "          if p.poll() is None:\n",
        "            p.send_signal(signal.SIGKILL)\n",
        "      except KeyboardInterrupt:\n",
        "        # Any interrupts that occur during shutdown should not propagate.\n",
        "        pass\n",
        "\n",
        "      if num_interrupts > 2:\n",
        "        # In practice, this shouldn't be possible since\n",
        "        # SIGKILL is quite effective.\n",
        "        raise\n",
        "\n",
        "\n",
        "def _poll_process(parent_pty, epoll, p, cmd, decoder, state):\n",
        "  \"\"\"Polls the process and captures / forwards input and output.\"\"\"\n",
        "\n",
        "  terminated = p.poll() is not None\n",
        "  if terminated:\n",
        "    termios.tcdrain(parent_pty)\n",
        "    # We're no longer interested in write events and only want to consume any\n",
        "    # remaining output from the terminated process. Continuing to watch write\n",
        "    # events may cause early termination of the loop if no output was\n",
        "    # available but the pty was ready for writing.\n",
        "    epoll.modify(parent_pty,\n",
        "                 (select.EPOLLIN | select.EPOLLHUP | select.EPOLLERR))\n",
        "\n",
        "  output_available = False\n",
        "\n",
        "  events = epoll.poll()\n",
        "  input_events = []\n",
        "  for _, event in events:\n",
        "    if event & select.EPOLLIN:\n",
        "      output_available = True\n",
        "      raw_contents = os.read(parent_pty, _PTY_READ_MAX_BYTES_FOR_TEST)\n",
        "      decoded_contents = decoder.decode(raw_contents)\n",
        "\n",
        "      sys.stdout.write(decoded_contents)\n",
        "      state.process_output.write(decoded_contents)\n",
        "\n",
        "    if event & select.EPOLLOUT:\n",
        "      # Queue polling for inputs behind processing output events.\n",
        "      input_events.append(event)\n",
        "\n",
        "    # PTY was disconnected or encountered a connection error. In either case,\n",
        "    # no new output should be made available.\n",
        "    if (event & select.EPOLLHUP) or (event & select.EPOLLERR):\n",
        "      state.is_pty_still_connected = False\n",
        "\n",
        "  for event in input_events:\n",
        "    # Check to see if there is any input on the stdin socket.\n",
        "    # pylint: disable=protected-access\n",
        "    input_line = _message._read_stdin_message()\n",
        "    # pylint: enable=protected-access\n",
        "    if input_line is not None:\n",
        "      # If a very large input or sequence of inputs is available, it's\n",
        "      # possible that the PTY buffer could be filled and this write call\n",
        "      # would block. To work around this, non-blocking writes and keeping\n",
        "      # a list of to-be-written inputs could be used. Empirically, the\n",
        "      # buffer limit is ~12K, which shouldn't be a problem in most\n",
        "      # scenarios. As such, optimizing for simplicity.\n",
        "      input_bytes = bytes(input_line.encode(_ENCODING))\n",
        "      os.write(parent_pty, input_bytes)\n",
        "\n",
        "  # Once the process is terminated, there still may be output to be read from\n",
        "  # the PTY. Wait until the PTY has been disconnected and no more data is\n",
        "  # available for read. Simply waiting for disconnect may be insufficient if\n",
        "  # there is more data made available on the PTY than we consume in a single\n",
        "  # read call.\n",
        "  if terminated and not state.is_pty_still_connected and not output_available:\n",
        "    sys.stdout.flush()\n",
        "    command_output = state.process_output.getvalue()\n",
        "    return ShellResult(cmd, p.returncode, command_output)\n",
        "\n",
        "  if not output_available:\n",
        "    # The PTY is almost continuously available for reading input to provide\n",
        "    # to the underlying subprocess. This means that the polling loop could\n",
        "    # effectively become a tight loop and use a large amount of CPU. Add a\n",
        "    # slight delay to give resources back to the system while monitoring the\n",
        "    # process.\n",
        "    # Skip this delay if we read output in the previous loop so that a partial\n",
        "    # read doesn't unnecessarily sleep before reading more output.\n",
        "    # TODO(b/115527726): Rather than sleep, poll for incoming messages from\n",
        "    # the frontend in the same poll as for the output.\n",
        "    time.sleep(0.1)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _display_stdin_widget(delay_millis=0):\n",
        "  \"\"\"Context manager that displays a stdin UI widget and hides it upon exit.\n",
        "  Args:\n",
        "    delay_millis: Duration (in milliseconds) to delay showing the widget within\n",
        "      the UI.\n",
        "  Yields:\n",
        "    A callback that can be invoked with a single argument indicating whether\n",
        "    echo is enabled.\n",
        "  \"\"\"\n",
        "  shell = _ipython.get_ipython()\n",
        "  display_args = ['cell_display_stdin', {'delayMillis': delay_millis}]\n",
        "  _message.send_request(\n",
        "      *display_args, parent=shell.parent_header, expect_reply=False)\n",
        "\n",
        "  def echo_updater(new_echo_status):\n",
        "    # Note: Updating the echo status uses colab_request / colab_reply on the\n",
        "    # stdin socket. Input provided by the user also sends messages on this\n",
        "    # socket. If user input is provided while the blocking_request call is still\n",
        "    # waiting for a colab_reply, the input will be dropped per\n",
        "    # https://github.com/googlecolab/colabtools/blob/56e4dbec7c4fa09fad51b60feb5c786c69d688c6/google/colab/_message.py#L100.\n",
        "    update_args = ['cell_update_stdin', {'echo': new_echo_status}]\n",
        "    _message.send_request(\n",
        "        *update_args, parent=shell.parent_header, expect_reply=False)\n",
        "\n",
        "  yield echo_updater\n",
        "\n",
        "  _message.send_request(\n",
        "      'cell_remove_stdin', {}, parent=shell.parent_header, expect_reply=False)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _no_op():\n",
        "  yield\n",
        "\n",
        "\n",
        "def _register_magics(ip):\n",
        "  ip.register_magic_function(\n",
        "      _shell_line_magic, magic_kind='line', magic_name='shell')\n",
        "  ip.register_magic_function(\n",
        "      _shell_cell_magic, magic_kind='cell', magic_name='shell')\n",
        "\n",
        "\n",
        "_INTERRUPTED_SIGNALS = (\n",
        "    signal.SIGINT,\n",
        "    signal.SIGTERM,\n",
        "    signal.SIGKILL,\n",
        ")\n",
        "\n",
        "\n",
        "def _getoutput_compat(shell, cmd, split=True, depth=0):\n",
        "  \"\"\"Compatibility function for IPython's built-in getoutput command.\n",
        "  The getoutput command has the following semantics:\n",
        "    * Returns a SList containing an array of output\n",
        "    * SList items are of type \"str\". In Python 2, the str object is utf-8\n",
        "      encoded. In Python 3, the \"str\" type already supports Unicode.\n",
        "    * The _exit_code attribute is not set\n",
        "    * If the process was interrupted, \"^C\" is printed.\n",
        "  Args:\n",
        "    shell: An InteractiveShell instance.\n",
        "    cmd: Command to execute. This is the same as the corresponding argument to\n",
        "      InteractiveShell.getoutput.\n",
        "    split: Same as the corresponding argument to InteractiveShell.getoutput.\n",
        "    depth: Same as the corresponding argument to InteractiveShell.getoutput.\n",
        "  Returns:\n",
        "    The output as a SList if split was true, otherwise an LSString.\n",
        "  \"\"\"\n",
        "  # We set a higher depth than the IPython system command since a shell object\n",
        "  # is expected to call this function, thus adding one level of nesting to the\n",
        "  # stack.\n",
        "  result = _run_command(\n",
        "      shell.var_expand(cmd, depth=depth + 2), clear_streamed_output=True)\n",
        "  if -result.returncode in _INTERRUPTED_SIGNALS:\n",
        "    print('^C')\n",
        "\n",
        "  output = result.output\n",
        "  if six.PY2:\n",
        "    # Backwards compatibility. Python 2 getoutput() expects the result as a\n",
        "    # str, not a unicode.\n",
        "    output = output.encode(_ENCODING)\n",
        "\n",
        "  if split:\n",
        "    return text.SList(output.splitlines())\n",
        "  else:\n",
        "    return text.LSString(output)\n",
        "\n",
        "\n",
        "def _system_compat(shell, cmd, also_return_output=False):\n",
        "  \"\"\"Compatibility function for IPython's built-in system command.\n",
        "  The system command has the following semantics:\n",
        "    * No return value, and thus the \"_\" variable is not set\n",
        "    * Sets the _exit_code variable to the return value of the called process\n",
        "    * Unicode characters are preserved\n",
        "    * If the process was interrupted, \"^C\" is printed.\n",
        "  Args:\n",
        "    shell: An InteractiveShell instance.\n",
        "    cmd: Command to execute. This is the same as the corresponding argument to\n",
        "      InteractiveShell.system_piped.\n",
        "    also_return_output: if True, return any output from this function, along\n",
        "      with printing it. Otherwise, print output and return None.\n",
        "  Returns:\n",
        "    LSString if also_return_output=True, else None.\n",
        "  \"\"\"\n",
        "  # We set a higher depth than the IPython system command since a shell object\n",
        "  # is expected to call this function, thus adding one level of nesting to the\n",
        "  # stack.\n",
        "  result = _run_command(\n",
        "      shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n",
        "  shell.user_ns['_exit_code'] = result.returncode\n",
        "  if -result.returncode in _INTERRUPTED_SIGNALS:\n",
        "    print('^C')\n",
        "\n",
        "  if also_return_output:\n",
        "    output = result.output\n",
        "    if six.PY2:\n",
        "      # Backwards compatibility. Python 2 getoutput() expects the result as a\n",
        "      # str, not a unicode.\n",
        "      output = output.encode(_ENCODING)\n",
        "    return text.LSString(output)"
      ],
      "metadata": {
        "id": "XqMOpvpxM5PO",
        "cellView": "form"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "l8jCmNq3Kth7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "yl3GlkH7MRVX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv('https://raw.githubusercontent.com/rhutikcodes/weather-prediction-ml-model-analysis/main/backend/weatherAUS.csv')\n",
        "df = df_raw"
      ],
      "metadata": {
        "id": "OqWnYS_aK2b-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "x = df.iloc[:, [1, 2, 3, 4, 7, 8, 9, 10, 11, 12,\n",
        "                13, 14, 15, 16, 17, 18, 19, 20, 21]].values\n",
        "y = df.iloc[:, -1].values.reshape(-1, 1)  # slicing genrates new list\n",
        "\n",
        "# dealing with invalid dataset\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "x = imputer.fit_transform(x)\n",
        "y = imputer.fit_transform(y)\n",
        "\n",
        "# Label Encoding\n",
        "le1 = LabelEncoder()\n",
        "x[:, 0] = le1.fit_transform(x[:, 0])\n",
        "le2 = LabelEncoder()\n",
        "x[:, 4] = le2.fit_transform(x[:, 4])\n",
        "le3 = LabelEncoder()\n",
        "x[:, 6] = le3.fit_transform(x[:, 6])\n",
        "le4 = LabelEncoder()\n",
        "x[:, 7] = le4.fit_transform(x[:, 7])\n",
        "le5 = LabelEncoder()\n",
        "x[:, -1] = le5.fit_transform(x[:, -1])\n",
        "le6 = LabelEncoder()\n",
        "y = le6.fit_transform(y)\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)\n",
        "\n",
        "# Split Dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "LoagxirjK8TO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rLXhXk8GM4_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from threading import Timer\n",
        "\n",
        "__version__ = \"1.0.2\"\n",
        "def run_lt():\n",
        "  if os.path.isfile('/usr/local/bin/lt'):\n",
        "    print(\"localtunnel is alreadty installed.\")\n",
        "  else:\n",
        "    _run_command(\"npm install -g localtunnel\", clear_streamed_output=False)\n",
        "  output = _run_command(\"lt --port 5000 --subdomain finalyearproject\", clear_streamed_output=False)\n",
        "  return output\n",
        "\n",
        "def start_lt():\n",
        "\tlt_adress = run_lt()\n",
        "\tprint(f'Hello {lt_adress}')\n",
        "\n",
        "def run_with_lt(app):\n",
        "    old_run = app.run\n",
        "\n",
        "    def new_run(*args, **kwargs):\n",
        "        port = kwargs.get('port', 5000)\n",
        "        thread = Timer(1, start_lt)\n",
        "        thread.setDaemon(True)\n",
        "        thread.start()\n",
        "        old_run(*args, **kwargs)\n",
        "    app.run = new_run"
      ],
      "metadata": {
        "id": "g3LXoRFzfeSo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j4cHa7pRjuqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flask_ngrok_example.py\n",
        "from flask import Flask\n",
        "from flask import jsonify \n",
        "import flask\n",
        "from flask_cors import CORS\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = False\n",
        "run_with_lt(app)  # Start ngrok when app is run\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def hello_world():\n",
        "    return \"Hello World\"\n",
        "\n",
        "# Random Forest\n",
        "@app.route('/randomForest', methods=['GET'])\n",
        "def train_random_forest():\n",
        "    print('training Random Forest')\n",
        "    classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    classifier.score(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    dict_a = {\"accuracy\": str(accuracy)}\n",
        "    print(dict_a)\n",
        "    return jsonify(dict_a)\n",
        "\n",
        "# Logistic Regression\n",
        "@app.route('/logisticRegression', methods=['GET'])\n",
        "def train_logistic_regression():\n",
        "    print('training logistic Regression')\n",
        "    classifier_logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "    classifier_logreg.fit(x_train, y_train)\n",
        "    y_pred_LR = classifier_logreg.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred_LR)\n",
        "    dict_a = {\"accuracy\": str(accuracy)}\n",
        "    print(dict_a)\n",
        "    return jsonify(dict_a)\n",
        "\n",
        "# Naive Bayes\n",
        "@app.route('/naiveBayes', methods=['GET'])\n",
        "def train_naive_bayes():\n",
        "    print('training naive bayes')\n",
        "    nbmodel = GaussianNB()\n",
        "    nbmodel.fit(x_train, y_train)\n",
        "    y_pred_nb = nbmodel.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred_nb)\n",
        "    dict_a = {\"accuracy\": str(accuracy)}\n",
        "    print(dict_a)\n",
        "    return jsonify(dict_a)\n",
        "\n",
        "# Support Vector Machine\n",
        "@app.route('/supportVectorMachine', methods=['GET'])\n",
        "def train_svm():\n",
        "    print('training svm')\n",
        "    svm_clf = SVC(kernel='linear')\n",
        "    svm_clf.fit(x_train, y_train)\n",
        "    y_pred_svm = svm_clf.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "    dict_a = {\"accuracy\": str(accuracy)}\n",
        "    print(dict_a)\n",
        "    return jsonify(dict_a)\n",
        "\n",
        "# Artificial Neural Network\n",
        "@app.route('/artificialNeuralNetwork', methods=['GET'])\n",
        "def train_ann():\n",
        "    print('training ann')\n",
        "    ann_clf = tf.keras.models.Sequential()\n",
        "    ann_clf.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
        "    ann_clf.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
        "    ann_clf.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    ann_clf.compile(optimizer=\"adam\",\n",
        "                    loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "    ann_clf.fit(x_train, y_train, batch_size=32, epochs=100)\n",
        "    y_pred_ann = ann_clf.predict(x_test)\n",
        "    y_pred_ann = (y_pred_ann > 0.5)\n",
        "    accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "    dict_a = {\"accuracy\": str(accuracy)}\n",
        "    print(dict_a)\n",
        "    return jsonify(dict_a)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host=\"0.0.0.0\", port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE5o7FpXJ0mg",
        "outputId": "c40b5e2b-f3e1-4c65-8603-7aaec373f2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 1.19s\n",
            "your url is: https://finalyearproject.loca.lt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [20/May/2022 14:35:17] \"\u001b[37mGET /naiveBayes HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training naive bayes\n",
            "{'accuracy': '0.8043531769752804'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q3Os423aJ0bk"
      }
    }
  ]
}